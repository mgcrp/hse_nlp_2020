{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnOwQNw5aUnZ",
        "outputId": "e2f41829-4e28-42f7-886b-ac400933b893",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.6/dist-packages (0.9.2)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.6.0)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (50.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fasttext) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t6ODKTLyQeR"
      },
      "source": [
        "import fasttext\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras_preprocessing import sequence\n",
        "from keras_preprocessing.text import Tokenizer\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W06Hquwry2s2",
        "outputId": "7eb274e3-2531-4c96-f646-c26b6efa24d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "df = pd.read_csv('tsd_train.csv')\n",
        "df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>spans</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...</td>\n",
              "      <td>Another violent and aggressive immigrant killi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[33, 34, 35, 36, 37, 38, 39]</td>\n",
              "      <td>I am 56 years old, I am not your fucking junio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0, 1, 2, 3]</td>\n",
              "      <td>Damn, a whole family. Sad indeed.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]</td>\n",
              "      <td>What a knucklehead. How can anyone not know th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[32, 33, 34, 35, 36, 37, 38]</td>\n",
              "      <td>\"who do you think should do the killing?\"\\n\\nA...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7934</th>\n",
              "      <td>[8, 9, 10, 11]</td>\n",
              "      <td>Another fool pipes in.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7935</th>\n",
              "      <td>[48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...</td>\n",
              "      <td>So if a restaurant owner puts up a sign saying...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7936</th>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n",
              "      <td>Any faith that can't stand up to logic and rea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7937</th>\n",
              "      <td>[5, 6, 7, 8, 9, 10, 11]</td>\n",
              "      <td>This idiotic. Use the surplus to pay down the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7938</th>\n",
              "      <td>[106, 107, 108, 109, 110, 169, 170, 171, 172, ...</td>\n",
              "      <td>Who is this \"we\" of which you speak? Are you r...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7939 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  spans                                               text\n",
              "0     [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,...  Another violent and aggressive immigrant killi...\n",
              "1                          [33, 34, 35, 36, 37, 38, 39]  I am 56 years old, I am not your fucking junio...\n",
              "2                                          [0, 1, 2, 3]                  Damn, a whole family. Sad indeed.\n",
              "3             [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]  What a knucklehead. How can anyone not know th...\n",
              "4                          [32, 33, 34, 35, 36, 37, 38]  \"who do you think should do the killing?\"\\n\\nA...\n",
              "...                                                 ...                                                ...\n",
              "7934                                     [8, 9, 10, 11]                             Another fool pipes in.\n",
              "7935  [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 5...  So if a restaurant owner puts up a sign saying...\n",
              "7936  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  Any faith that can't stand up to logic and rea...\n",
              "7937                            [5, 6, 7, 8, 9, 10, 11]  This idiotic. Use the surplus to pay down the ...\n",
              "7938  [106, 107, 108, 109, 110, 169, 170, 171, 172, ...  Who is this \"we\" of which you speak? Are you r...\n",
              "\n",
              "[7939 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thWKikhO4Lu0"
      },
      "source": [
        "import re\n",
        "#предобработка текста\n",
        "def list_replace(search, replacement, text):\n",
        "    \"\"\"\n",
        "    Replaces all symbols of text which are present\n",
        "    in the search string with the replacement string.\n",
        "    \"\"\"\n",
        "    search = [el for el in search if el in text]\n",
        "    for c in search:\n",
        "        text = text.replace(c, replacement)\n",
        "    return text\n",
        "\n",
        "def clean_text(text):\n",
        "\n",
        "    text = list_replace \\\n",
        "        ('\\u00AB\\u00BB\\u2039\\u203A\\u201E\\u201A\\u201C\\u201F\\u2018\\u201B\\u201D\\u2019', '\\u0022', text)\n",
        "\n",
        "    text = list_replace \\\n",
        "        ('\\u2012\\u2013\\u2014\\u2015\\u203E\\u0305\\u00AF', '\\u2003\\u002D\\u002D\\u2003', text)\n",
        "\n",
        "    text = list_replace('\\u2010\\u2011', '\\u002D', text)\n",
        "\n",
        "    text = list_replace \\\n",
        "            (\n",
        "            '\\u2000\\u2001\\u2002\\u2004\\u2005\\u2006\\u2007\\u2008\\u2009\\u200A\\u200B\\u202F\\u205F\\u2060\\u3000',\n",
        "            '\\u2002', text)\n",
        "\n",
        "    text = re.sub('\\u2003\\u2003', '\\u2003', text)\n",
        "    text = re.sub('\\t\\t', '\\t', text)\n",
        "\n",
        "    text = list_replace \\\n",
        "            (\n",
        "            '\\u02CC\\u0307\\u0323\\u2022\\u2023\\u2043\\u204C\\u204D\\u2219\\u25E6\\u00B7\\u00D7\\u22C5\\u2219\\u2062',\n",
        "            '.', text)\n",
        "\n",
        "    text = list_replace('\\u2217', '\\u002A', text)\n",
        "\n",
        "    text = list_replace('\\u00C4', 'A', text)\n",
        "    text = list_replace('\\u00E4', 'a', text)\n",
        "    text = list_replace('\\u00CB', 'E', text)\n",
        "    text = list_replace('\\u00EB', 'e', text)\n",
        "    text = list_replace('\\u1E26', 'H', text)\n",
        "    text = list_replace('\\u1E27', 'h', text)\n",
        "    text = list_replace('\\u00CF', 'I', text)\n",
        "    text = list_replace('\\u00EF', 'i', text)\n",
        "    text = list_replace('\\u00D6', 'O', text)\n",
        "    text = list_replace('\\u00F6', 'o', text)\n",
        "    text = list_replace('\\u00DC', 'U', text)\n",
        "    text = list_replace('\\u00FC', 'u', text)\n",
        "    text = list_replace('\\u0178', 'Y', text)\n",
        "    text = list_replace('\\u00FF', 'y', text)\n",
        "    text = list_replace('\\u00DF', 's', text)\n",
        "    text = list_replace('\\u1E9E', 'S', text)\n",
        "    # Removing punctuation\n",
        "    text = list_replace(',.[]{}()=+-−*&^%$#@!~;:§/\\|\\?\"\\n', ' ', text)\n",
        "    # Replacing all numbers with masks\n",
        "    text = list_replace('0123456789', 'x', text)\n",
        "\n",
        "    return text"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjZL3lVcc71j"
      },
      "source": [
        "#Переходим от символов к словам\n",
        "X = [[]]\n",
        "y = [[]]\n",
        "for i in range(df.shape[0]):\n",
        "    cl_text = clean_text(df.iloc[i,1])\n",
        "    fl = np.zeros(len(cl_text))\n",
        "    if(len(df.iloc[i,0]) > 2):\n",
        "        arr = [int(a) for a in df.iloc[i,0][1:-1].split(', ')]\n",
        "        fl[arr] = 1\n",
        "    spl = cl_text.split(' ')\n",
        "    prev_len = 0\n",
        "    X_i = []\n",
        "    y_i = []\n",
        "    for j in range(len(spl)):\n",
        "        if(len(spl[j]) > 0):\n",
        "            X_i.append(spl[j])\n",
        "            y_i.append(sum(fl[prev_len:prev_len+len(spl[j])])/len(spl[j]))\n",
        "        prev_len = prev_len + len(spl[j]) + 1\n",
        "    X.append(X_i)\n",
        "    y.append(y_i)\n",
        "X = X[1:]\n",
        "y = y[1:]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTVZypAC4Ocj",
        "outputId": "f9e6b344-a545-4b86-82e1-5dabbdd2fef5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cleaned_train_texts = [' '.join(i) for i in X]\n",
        "maxlen = max([len(i) for i in X])\n",
        "maxlen"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "201"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gl8y-A7rPL3",
        "outputId": "32163257-b59a-479a-8919-94143907fa5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "! wget -O model_fasttext.bin https://www.dropbox.com/s/f8svib34687gyb4/rudrec_fasttext_model.bin?dl=0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-08 11:49:09--  https://www.dropbox.com/s/f8svib34687gyb4/rudrec_fasttext_model.bin?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.1, 2620:100:601d:1::a27d:501\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/f8svib34687gyb4/rudrec_fasttext_model.bin [following]\n",
            "--2020-11-08 11:49:09--  https://www.dropbox.com/s/raw/f8svib34687gyb4/rudrec_fasttext_model.bin\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com/cd/0/inline/BCwk_wj4s1I4QgeXaDVDfyV5wG50sdhp__WfMvX-rHOBax_00vUhm2OiBwVC65Wl6fk00LSoxSLyDJOMxc5Lc0zCJXFzZwPKCN6sMFYuozfT4sxqk2OuNoP4YwWSRnGxcoQ/file# [following]\n",
            "--2020-11-08 11:49:09--  https://ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com/cd/0/inline/BCwk_wj4s1I4QgeXaDVDfyV5wG50sdhp__WfMvX-rHOBax_00vUhm2OiBwVC65Wl6fk00LSoxSLyDJOMxc5Lc0zCJXFzZwPKCN6sMFYuozfT4sxqk2OuNoP4YwWSRnGxcoQ/file\n",
            "Resolving ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com (ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com)... 162.125.9.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com (ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com)|162.125.9.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BCw7kZQ57CD1GIQ8R3Ex2vmXtETgHtn9UgTURFyyR_gI1nyY3g8B2amQ6jucl1MBnaoGbdaxZcKess0Z0W16HCvF1m5bS9PsBL1th5l62GvHL8-7bIODGqg_Tcfj2E2p-Q5zJXPoWJYcoFe2vl6bDmC0HQHt1lFSupSvxk5yWkp_445ZrkFNnD-tmavs_3tdPQ84CeMOqRaQjkAv6pme7ZB8gN4ux3JzSa9bnVlLgJ49kywypqv4UDw1n-vXqE7PXqEjwil9jj5QK7pAhgjujbeDNFP8UpXDKiNsl2CNFx_I9SdgcvpVpU7hlzVRqL1HfBJvgD_L5iNFBCOcUGEhj0uHU4ZzttvA7_q-8zimjPf96A/file [following]\n",
            "--2020-11-08 11:49:10--  https://ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com/cd/0/inline2/BCw7kZQ57CD1GIQ8R3Ex2vmXtETgHtn9UgTURFyyR_gI1nyY3g8B2amQ6jucl1MBnaoGbdaxZcKess0Z0W16HCvF1m5bS9PsBL1th5l62GvHL8-7bIODGqg_Tcfj2E2p-Q5zJXPoWJYcoFe2vl6bDmC0HQHt1lFSupSvxk5yWkp_445ZrkFNnD-tmavs_3tdPQ84CeMOqRaQjkAv6pme7ZB8gN4ux3JzSa9bnVlLgJ49kywypqv4UDw1n-vXqE7PXqEjwil9jj5QK7pAhgjujbeDNFP8UpXDKiNsl2CNFx_I9SdgcvpVpU7hlzVRqL1HfBJvgD_L5iNFBCOcUGEhj0uHU4ZzttvA7_q-8zimjPf96A/file\n",
            "Reusing existing connection to ucb149ce8b5cf8d0ecde19706764.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2048104027 (1.9G) [application/octet-stream]\n",
            "Saving to: ‘model_fasttext.bin’\n",
            "\n",
            "model_fasttext.bin  100%[===================>]   1.91G  86.3MB/s    in 23s     \n",
            "\n",
            "2020-11-08 11:49:34 (83.2 MB/s) - ‘model_fasttext.bin’ saved [2048104027/2048104027]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zY-LewJb4100",
        "outputId": "6e1382c8-1d83-4f5a-ac09-5d519be17349",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Загружаем предобученную fasttext модель\n",
        "fasttext_model_path = 'model_fasttext.bin'\n",
        "fasttext_model = fasttext.load_model(fasttext_model_path)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeXjiPwi4Qcf"
      },
      "source": [
        "#Получаем эмбеддинги\n",
        "EMBEDDINGS_DIM = 200\n",
        "tokenizer = Tokenizer(lower=True, char_level=False)\n",
        "tokenizer.fit_on_texts(cleaned_train_texts)\n",
        "word_seq_train = tokenizer.texts_to_sequences(cleaned_train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "trash = []\n",
        "for i in range(len(X)):\n",
        "    if(len(X[i]) != len(word_seq_train[i])):\n",
        "        trash.append(i)\n",
        "for i in trash:\n",
        "    word_seq_train.pop(i)\n",
        "    X.pop(i)\n",
        "    y.pop(i)\n",
        "  \n",
        "#Дополняем нулями до длины maxlen\n",
        "word_seq_train = sequence.pad_sequences(word_seq_train, maxlen=maxlen, padding=\"post\")\n",
        "\n",
        "dictionary_size = len(word_index.keys())\n",
        "embedding_matrix = np.zeros((dictionary_size + 1, EMBEDDINGS_DIM))\\\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = fasttext_model.get_word_vector((word))\n",
        "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oX0_1DDMyeJc"
      },
      "source": [
        "#Дополняем нулями до длины maxlen\n",
        "y = sequence.pad_sequences(y, maxlen=maxlen, padding=\"post\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFKOSSYApAg9"
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "#Модель со слоем эмбеддингов, двунаправленным LSTM и полносвязным слоем к каждлму из выходов BiLSTM\n",
        "input = Input(shape=(maxlen,))\n",
        "out = Embedding(len(word_index.keys())+1, 200, input_length=maxlen, weights=[embedding_matrix])(input)\n",
        "out = Dropout(0.1)(out)\n",
        "out = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(out)\n",
        "out = TimeDistributed(Dense(1, activation=\"sigmoid\"))(out)\n",
        "model = Model(input, out)\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LIZM6RsQas6"
      },
      "source": [
        "#Разбиваем выборку на обучающую и тестовую и обучаем\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(word_seq_train, y, test_size=0.2)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBM2tnlHw3n4",
        "outputId": "f1f55613-5d28-48fa-d345-0a422231869d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=32, epochs=3, validation_split=0.1, verbose=1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "178/178 [==============================] - 161s 906ms/step - loss: 0.0812 - accuracy: 0.9835 - val_loss: 0.0399 - val_accuracy: 0.9877\n",
            "Epoch 2/3\n",
            "178/178 [==============================] - 161s 904ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.0363 - val_accuracy: 0.9889\n",
            "Epoch 3/3\n",
            "178/178 [==============================] - 164s 920ms/step - loss: 0.0391 - accuracy: 0.9879 - val_loss: 0.0367 - val_accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe2020edba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHeyFoT20PO8"
      },
      "source": [
        "pr = model.predict(X_test).reshape(y_test.shape)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGCwMLCJQ0wO",
        "outputId": "912791df-712d-486a-e130-c22944c96895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "np.mean(tf.keras.losses.binary_crossentropy(y_test, pr.reshape(y_test.shape)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.039707605"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UQfzhpo3Izk"
      },
      "source": [
        "#Приводим выход к нужному формату для корректного подсчёта f1-score\n",
        "import tensorflow as tf\n",
        "arr1 = []\n",
        "arr2 = []\n",
        "for i in range(X_test.shape[0]):\n",
        "    l = len(X_test[i])\n",
        "    arr1.append([round(i) for i in list(pr[i][:l])])\n",
        "    arr2.append(list(y_test[i][:l]))"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTxzFHtnpF80",
        "outputId": "308c0da2-4ce5-4e15-8c64-842942de66f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "np.mean([f1_score(arr2[i], arr1[i]) for i in range(len(arr2))])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1515: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  average, \"true nor predicted\", 'F-score is', len(true_sum)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.588948730960844"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    }
  ]
}